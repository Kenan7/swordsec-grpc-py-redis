# SwordSec backend task

## Kurulum

```bash
docker-compose up --build --scale rq-worker=5
```

## Protobufs

UsersService de iki ana methodumuz var

- SendUserInfo (unary - unary)
    - tek istek gÃ¶nderip karÅŸÄ±lÄ±ÄŸÄ±nda tek cevap alÄ±yoruz

- SendUserInfoClientStream (stream - unary)
    - Ã§oÄŸul istek gÃ¶nderip karÅŸÄ±lÄ±ÄŸÄ±nda tek cevap alÄ±yoruz


```proto
service Users {
    rpc SendUserInfo (UserRequest) returns (UserResponse);
    rpc SendUserInfoClientStream (stream UserRequest) returns (UserResponse);
}
```

Ä°stemcinin Ã§oÄŸul istek gÃ¶ndermesi durumu da uygun geldi bana, bu yÃ¼zden onu da eklemke istedim.

ClientStream Ã§oklu istekler Ã¼retip sunucuya gÃ¶nderiyor ve sonucunda da tek cevap alÄ±yor sunucudan.

Bizim de sunucuya kullanÄ±cÄ± verilerini gÃ¶ndereceÄŸimizi hesaba katarak, kullanÄ±cÄ± veri akÄ±mÄ± oluÅŸtura biliriz.


## Ä°stemci

Ä°stekleri oluÅŸturduÄŸumuz kÄ±sÄ±m burasÄ± oluyor
```py
def process_users_from_json_files():
    ...
    for user in json_content:
        yield UserRequest(**user)
    ...
```

burasÄ± da istekleri sunucuya gÃ¶nderdiÄŸimiz kÄ±sÄ±m
```py
def client_stream():
    users_client.SendUserInfo(
        process_users_from_json_files()
    )
```

Tamam, istemciden veri akÄ±mÄ± yapmak iyi, hoÅŸ ama aslÄ±nda birli methodu kullandÄ±m ana fonksiyon olarak


`main()` fonksiyonum ðŸ‘‡ðŸ»

```py
def main():
    log.info("Client initialized...")
    for _user in process_users_from_json_files():
        ...
            user_response = users_client.SendUserInfo(
                _user
            )
        ...
```

her iki yÃ¶ntem uygun bence, sadece projenin gereÄŸine gÃ¶re istediÄŸimizi kullanabileceÄŸimizi gÃ¶stermek istedim.


## Sunucu

Bu kÄ±sÄ±mda sunucunun gelen isteklerle nasÄ±l baÅŸa Ã§Ä±ktÄ±ÄŸÄ±nÄ± gÃ¶steriyor


veri geldiÄŸi zaman `process_incoming_request()` fonksiyonunu parametresi ile birlikte kuyruÄŸa ekliyoruz 

```py
def process_incoming_request(self, _data):

    self.data.update(
        MessageToDict(_data)
    )

    return UserResponse(status=True, message="ok")
```


```py
def SendUserInfo(self, request, context):
    log.info(f'incoming request -> {request}')
    q.enqueue(self.process_incoming_request, request)
```


istemciden veri akÄ±mÄ± (client stream) yaptÄ±ÄŸÄ±mÄ±z zaman sunucuda durum farklÄ± oluyor


bu zaman, kodun daha anlaÅŸÄ±lÄ±r olmasÄ± iÃ§in isimlendirmeyi de `request` den `request_iterator` -e deÄŸiÅŸtirip, dÃ¶ngÃ¼ye alÄ±yoruz



```py
def SendUserInfoClientStream(self, request_iterator, context):

    for request in request_iterator:
        log.info(f'incoming request (client stream) -> {request}')

        q.enqueue(self.process_incoming_request, request)

    try:
        q.enqueue(self.write_to_json_file, file_name='all_users.json')

        return UserResponse(status=True, message="ok")
    except:
        return UserResponse(status=False, message="not ok")
```


gelen akÄ±mÄ± kuyruÄŸa ekledikten sonra `write_to_json_file()` methodunu Ã§aÄŸÄ±rÄ±p topladÄ±ÄŸÄ±mÄ±z verileri dosyaya kaydedebiliriz


burada Ã¶zellikle dosyaya kaydetme methodunu da kuyruÄŸa ekledim. Ã§Ã¼nkÃ¼ bu methoda gelene kadar daha kuyruktaki iÅŸlemlerin bitmemesi ihtimali var. bu methodu da kuyruÄŸa ekleyerek en sonda Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan emin olabiliyoruz


## Docker dosyalarÄ±


Bu kÄ±sÄ±mda docker dosyalarÄ±nÄ± nasÄ±l Ã¶zelleÅŸtirdiÄŸimi gÃ¶stermek istiyorum.


genel olarak blog yazÄ±larÄ±nda bÃ¶yle bir dÃ¼zen gÃ¶rÃ¼yoruz, bu arada benimde docker dosyasÄ±nÄ±n ilk halini aldÄ±ÄŸÄ±m yer burda [(real python)](https://realpython.com/python-microservices-grpc/#docker)



ama tabii ki bunu optimize edebiliriz..


neden projenin iÃ§eriÄŸini kopyaladÄ±ktan sonra pip paketlerini kurmaya Ã§alÄ±ÅŸÄ±yoruz ki?


bu soruyu ilk kez kendime tutoriallardaki dokcer dosyalarÄ±nÄ±n dÃ¼zenini gÃ¶rdÃ¼ÄŸÃ¼m zaman vermiÅŸtim (django deploymenti daha yeni Ã¶ÄŸrendiÄŸim zamanlarda)


projede herhangi nokta, harf bile deÄŸiÅŸtirsek tÃ¼m gereksinimleri yeniden kurmaya Ã§alÄ±ÅŸacak



optimize ede bileceÄŸimiz birÅŸey, neden boÅŸuna zamanÄ±mÄ±zÄ± Ã§alsÄ±n ki? hem docker bizim iÃ§in keÅŸ sistemi kurdu o kadar. niye deÄŸerlendirmiyoruz?



en azÄ±ndan ben deÄŸerlendirmeye Ã§alÄ±ÅŸtÄ±m..


#### varsayÄ±lan docker dosyasÄ±

```Dockerfile
FROM python:3.8-slim

RUN mkdir /service

# COPY protobufs/ /service/protobufs/
COPY . /service/client/

WORKDIR /service/client

RUN pip install -r requirements.txt
RUN python -m grpc_tools.protoc -I protobufs --python_out=. \
           --grpc_python_out=. protobufs/users.proto


EXPOSE 50051
ENTRYPOINT [ "python", "client.py" ]
```

#### Ã¶zelleÅŸtirdiÄŸim docker dosyasÄ±

```Dockerfile
...

RUN mkdir /service
WORKDIR /service/client


COPY requirements.txt .
RUN pip install -r requirements.txt


COPY . .

...
```


gÃ¶rÃ¼yor musunuz? projenin iÃ§eriÄŸini en sonda kopyalÄ±yoruz docker container-e, gereksinimleri kurduktan sonra. ÅŸimdi herhangi bir deÄŸiÅŸiklik yapsak bile (requirements dÄ±ÅŸÄ±nda) keÅŸ kullanÄ±lacak, gereksinimler yeniden kurulmayacak.


aslÄ±nda bu esnada bi' kahve iÃ§ebilirdik ama.. neyse artÄ±k kahve falan yok bize..



## Docker-compose

[docker-compose](./docker-compose.yml) dosyamÄ±zda pek aÃ§Ä±klanacak birÅŸey yok aslÄ±nda, sadece worker kÄ±smÄ±nÄ± gÃ¶stermek istiyorum


iki seÃ§im koydum, ya python ile Ã§alÄ±ÅŸtÄ±racaÄŸÄ±z worker modÃ¼lÃ¼nÃ¼ 


YA DA


docker hub-dan (umarÄ±z ki gÃ¼vendiÄŸimiz birinden) hazÄ±r imajÄ± kullanarak


```yml
worker:
    build: worker # ./worker
    networks:
        - microservices
    environment:
        - REDIS_HOST=redis
        - REDIS_PORT=6379
    depends_on:
        - server
        - redis

    #  OR ðŸ‘‡ðŸ»

    rq-worker:
        image: jaredv/rq-docker:0.0.2
        command: rq worker -u redis://redis:6379 high normal low

        networks:
            - microservices

        depends_on:
            - redis

    rq-dashboard:
        image: jaredv/rq-docker:0.0.2 
        command: rq-dashboard -H rq-server
        ports:
        - 9181:9181
        
        networks:
            - microservices

        depends_on:
            - redis
```

kuyruÄŸu gÃ¶zlemlemek istemeÄŸimizi ihtimale alarak `rq-dashboard` da ekledim,


en sonda da, bu servislerin sÄ±ralamasÄ±nÄ± nasÄ±l kurduÄŸumu gÃ¶stermek istiyorum. redis serveri en sonda baÅŸlatmak istemeyiz, deÄŸil mi?


- redis (sunucu)
- gRPC sunucu (redis sunucusundan asÄ±lÄ±dÄ±r)
- gRPC client (gRPC sunucusundan asÄ±lÄ±dÄ±r)
- python redis queue worker (hem gRPC hem de redis sunucusundan asÄ±lÄ±dÄ±r)
- rq-dashboard (redis sunucusundan asÄ±lÄ±dÄ±r)



Projeyle ilgili herhangi bir sorunuz olursa da -> [mirkanan.k@labrin.tech](mailto:mirkanan.k@labrin.tech)